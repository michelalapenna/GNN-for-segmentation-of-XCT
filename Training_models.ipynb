{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "from utils import*\n",
    "from models import*\n",
    "from seed_everything import*\n",
    "from Train_Eval_Test import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Hyperparameters of the model\n",
    "\n",
    "args = {\n",
    "    'device': device,\n",
    "    'heads': 2,\n",
    "    'num_features' : 1,\n",
    "    'hidden' : 100, # 100 for simple GNN, 50 for ViG model\n",
    "    'num_classes' : 6,\n",
    "    'dropout': 0.001,\n",
    "    'alpha' : 0.1,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 200,\n",
    "    'patience': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 512 # The side of the original volume\n",
    "new_side = 64 # The side of the sub-volume on which we construct the graph\n",
    "stride = 56 # The stride we use in extracting the overlapping sub-volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the synthetic non-augmented dataset (train/val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = raw_to_tensor(\"FINAL1.raw\", side)\n",
    "features_2 = raw_to_tensor(\"FINAL2.raw\", side)\n",
    "features_3 = raw_to_tensor(\"FINAL3.raw\", side)\n",
    "features_4 = raw_to_tensor(\"FINAL4.raw\", side)\n",
    "features_5 = raw_to_tensor(\"FINAL5.raw\", side)\n",
    "features_6 = raw_to_tensor(\"FINAL6.raw\", side)\n",
    "features_7 = raw_to_tensor(\"FINAL7.raw\", side)\n",
    "\n",
    "\n",
    "labels_1 = raw_to_tensor(\"LABELS1.raw\", side)\n",
    "labels_2 = raw_to_tensor(\"LABELS2.raw\", side)\n",
    "labels_3 = raw_to_tensor(\"LABELS3.raw\", side)\n",
    "labels_4 = raw_to_tensor(\"LABELS4.raw\", side)\n",
    "labels_5 = raw_to_tensor(\"LABELS5.raw\", side)\n",
    "labels_6 = raw_to_tensor(\"LABELS6.raw\", side)\n",
    "labels_7 = raw_to_tensor(\"LABELS7.raw\", side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the average occurrence of the 6 classes among the 8 volumes (train/val and test) once and we save it to a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_1 = average_labels_vol(labels_1,side)\n",
    "occ_2 = average_labels_vol(labels_2,side)\n",
    "occ_3 = average_labels_vol(labels_3,side)\n",
    "occ_4 = average_labels_vol(labels_4,side)\n",
    "occ_5 = average_labels_vol(labels_5,side)\n",
    "occ_6 = average_labels_vol(labels_6,side)\n",
    "occ_7 = average_labels_vol(labels_7,side)\n",
    "occ_test = average_labels_vol(labels_test,side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = (np.array(occ_1) + np.array(occ_2) + np.array(occ_3) + np.array(occ_4) + np.array(occ_5) + np.array(occ_6) + np.array(occ_7) + np.array(occ_test))/7\n",
    "\n",
    "norm_av = (av[:])/(np.sum(av[:]))\n",
    "inverse_norm_av = (1/norm_av).reshape(-1)\n",
    "np.save('weights_loss.npy', inverse_norm_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract 64x64x64 overlapping sub-volumes from the original volumes with a stride of 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(view_as_windows(features_1.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "x2 = torch.tensor(view_as_windows(features_2.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "x3 = torch.tensor(view_as_windows(features_3.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "x4 = torch.tensor(view_as_windows(features_4.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "x5 = torch.tensor(view_as_windows(features_5.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "x6 = torch.tensor(view_as_windows(features_6.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "x7 = torch.tensor(view_as_windows(features_7.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "\n",
    "y1 = torch.tensor(view_as_windows(labels_1.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y2 = torch.tensor(view_as_windows(labels_2.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y3 = torch.tensor(view_as_windows(labels_3.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y4 = torch.tensor(view_as_windows(labels_4.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y5 = torch.tensor(view_as_windows(labels_5.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y6 = torch.tensor(view_as_windows(labels_6.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y7 = torch.tensor(view_as_windows(labels_7.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the synthetic augmented dataset (train/val), where the volumes have already size 64x64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = pd.read_csv('Training_Set.csv')\n",
    "\n",
    "Val_df = pd.read_csv('Validation_Set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = torch.tensor(np.array(list(map(fromfile, Train_df.iloc[:,0].to_numpy().reshape(-1)))))\n",
    "Y_Train = torch.tensor(np.array(list(map(fromfile, Train_df.iloc[:,1].to_numpy().reshape(-1)))))\n",
    "\n",
    "X_Val = torch.tensor(np.array(list(map(fromfile, Val_df.iloc[:,0].to_numpy().reshape(-1)))))\n",
    "Y_Val = torch.tensor(np.array(list(map(fromfile, Val_df.iloc[:,1].to_numpy().reshape(-1)))))\n",
    "\n",
    "X_Train = X_Train.reshape(-1, new_side**3, 1)\n",
    "X_Val = X_Val.reshape(-1, new_side**3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import experimental subvolume for fine-tuning and the stride is reduced to 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvolume = np.load('subvolume_128.npy').reshape(128,128,128)\n",
    "labels = np.load('labels_128.npy').reshape(128,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(view_as_windows(subvolume, (new_side,new_side,new_side), step=28).reshape(-1,new_side**3,1))\n",
    "\n",
    "y_train = torch.tensor(view_as_windows(labels, (new_side,new_side,new_side), step=28).reshape(-1,new_side**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_norm_av = torch.load(\"weights_loss.npy\")\n",
    "inverse_norm_av[0] = 0 # do not want to optimize wrt voids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, 23.1316, 25.6455,  9.6994, 22.6797,  1.3000],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_norm_av"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a graph from each sub-volume by connecting each voxel to its nearest 6 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh = 6\n",
    "\n",
    "cloud = torch.cartesian_prod(torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)))\n",
    "edges = create_edges(k_neigh, cloud)\n",
    "adj = SparseTensor(row=edges[0], col=edges[1], sparse_sizes=(new_side**3,new_side**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the dataset for training and validation after shuffling the subvolumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-augmented dataset for simple GNN\n",
    "\n",
    "data_list = []\n",
    "\n",
    "def data_list_creation(X, Y, edges):\n",
    "  for i in range(X.size()[0]):\n",
    "    data_list.append(Data(x=X[i], edge_index=edges, y=Y[i]))\n",
    "\n",
    "data_list_creation(x1, y1, edges)\n",
    "data_list_creation(x2, y2, edges)\n",
    "data_list_creation(x3, y3, edges)\n",
    "data_list_creation(x4, y4, edges)\n",
    "data_list_creation(x5, y5, edges)\n",
    "data_list_creation(x6, y6, edges)\n",
    "data_list_creation(x7, y7, edges)\n",
    "\n",
    "random.Random(4).shuffle(data_list) # We fix it to make it reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented dataset for ViG\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(X_Train.size()[0]):\n",
    "    data_list.append(Data(x=X_Train[i], y=Y_Train[i], adj_t=adj))\n",
    "\n",
    "for i in range(X_Val.size()[0]):\n",
    "    data_list.append(Data(x=X_Val[i], y=Y_Val[i], adj_t=adj))\n",
    "\n",
    "random.Random(4).shuffle(data_list) # We fix it to make it reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental subvolume for fine-tuning\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(x_train.size()[0]):\n",
    "    data_list.append(Data(x=x_train[i], adj_t=adj, y=y_train[i]))\n",
    "\n",
    "random.Random(4).shuffle(data_list) # We fix it to make it reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the adjacency matrix of the graph occupies a lot of memory, we set the batch size to 4 and backpropagate every 16 steps to simulate a batch size of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list[:int(0.7*len(data_list))], batch_size=batch, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(data_list[int(0.7*len(data_list)):], batch_size=batch, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the stop variable to eliminate the loss vector from memory while training the model until the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = len(data_list[:int(0.7*len(data_list))])//batch + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'ViG') # directory in which we save the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    seed_everything(i) # we fix it to make it reproducible\n",
    "\n",
    "    model = ViG(batch, new_side, args['num_features'], args['hidden'], args['num_classes'], args['dropout']).to(device)\n",
    "    model.reset_parameters()\n",
    "\n",
    "    # when fine-tuning we load the model and do not reset the parameters\n",
    "    model.load_state_dict(torch.load('ViG_' + str(i) + '.h5'))\n",
    "\n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    accuracies_train = []\n",
    "    accuracies_val = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=0.001)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=inverse_norm_av.type(torch.FloatTensor).to(device)) \n",
    "\n",
    "    decayRate = 0.96\n",
    "    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "    #Initialize Variables for EarlyStopping\n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    patience = args['patience']\n",
    "\n",
    "    for epoch in range(1, 1 + args['epochs']): #\n",
    "        \n",
    "        print('Training...')\n",
    "        model = model.float()\n",
    "        train_obj = Train(model, device, train_loader, optimizer, loss_fn, stop)\n",
    "        loss = train_obj.train_function()\n",
    "        losses_train.append(loss)\n",
    "        my_lr_scheduler.step()\n",
    "\n",
    "        eval_obj = Eval(model, device, loss_fn, args['classes'])\n",
    "        _, train_acc_per_class = eval_obj.eval_function(train_loader, Dice=True)\n",
    "        val_loss, val_acc_per_class = eval_obj.eval_function(val_loader, Dice=True)\n",
    "        losses_val.append(val_loss)\n",
    "\n",
    "        acc_train = np.mean(np.array(train_acc_per_class), axis=0)\n",
    "        accuracies_train.append(acc_train)\n",
    "\n",
    "        acc_val = np.mean(np.array(val_acc_per_class), axis=0)\n",
    "        accuracies_val.append(acc_val)\n",
    "\n",
    "        print([epoch, 100 * train_acc_per_class[1], 100 * train_acc_per_class[2], 100 * train_acc_per_class[3], 100 * train_acc_per_class[4], 100 * train_acc_per_class[5],\n",
    "                      100 * val_acc_per_class[1], 100 * val_acc_per_class[2], 100 * val_acc_per_class[3], 100 * val_acc_per_class[4], 100 * val_acc_per_class[5]])\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict()) # Deep copy here      \n",
    "            patience = args['patience']  # Reset patience counter\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "\n",
    "                eval_obj = Eval(model, device, loss_fn, args['classes'])\n",
    "                _, train_acc_per_class = eval_obj.eval_function(train_loader, Dice=True) \n",
    "                _, val_acc_per_class = eval_obj.eval_function(val_loader, Dice=True) \n",
    "                \n",
    "                data = [epoch, \n",
    "                        100 * train_acc_per_class[1], 100 * train_acc_per_class[2], 100 * train_acc_per_class[3], 100 * train_acc_per_class[4], 100 * train_acc_per_class[5],\n",
    "                        100 * val_acc_per_class[1], 100 * val_acc_per_class[2], 100 * val_acc_per_class[3], 100 * val_acc_per_class[4], 100 * val_acc_per_class[5]]\n",
    "                \n",
    "                with open('Train_Val_Synthetic_ViG.csv', 'a') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data)\n",
    "\n",
    "                break\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "        \n",
    "    model_name = 'ViG_' + str(i) + '.h5'\n",
    "\n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    plt.plot(range(len(accuracies_train)), accuracies_train)\n",
    "    plt.title(\"Accuracy on the training set\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.savefig(\"Accuracy_ViG_\" + str(i))\n",
    "\n",
    "    plt.plot(range(len(accuracies_val)), accuracies_val)\n",
    "    plt.title(\"Accuracy on the validation set\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.savefig(\"Accuracy_ViG_\" + str(i))\n",
    "\n",
    "    plt.plot(range(len(losses_train)), losses_train)\n",
    "    plt.title(\"Loss on the training set\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss_ViG_\" + str(i))\n",
    "\n",
    "    plt.plot(range(len(losses_val)), losses_val)\n",
    "    plt.title(\"Loss on the validation set\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss_ViG_\" + str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michelaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
