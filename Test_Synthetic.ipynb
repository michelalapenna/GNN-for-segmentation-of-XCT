{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "from utils import*\n",
    "from models import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to feed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': device,\n",
    "    'heads': 2,\n",
    "    'num_features' : 1,\n",
    "    'hidden' : 100,\n",
    "    'num_classes' : 6,\n",
    "    'dropout': 0.001,\n",
    "    'alpha' : 0.1,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 512 # The side of the original volume\n",
    "new_side = 64 # The side of the sub-volume on which we construct the graph\n",
    "stride = 28 # The stride we use in extracting the overlapping sub-volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the features and the labels of the synthetic volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = raw_to_tensor(\"CVSynth.raw\", side)\n",
    "\n",
    "labels_test = raw_to_tensor(\"CVSynth_Labels.raw\", side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the first slice of labels to compare it with the model's segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels_test[0], vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels\")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we extract the sub-volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(view_as_windows(features_test.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3,1))\n",
    "\n",
    "y_test = torch.tensor(view_as_windows(labels_test.numpy(), (new_side,new_side,new_side), step=stride).reshape(-1,new_side**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of edges connecting each node to its first 6 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = torch.cartesian_prod(torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)))\n",
    "\n",
    "k_neigh = 6\n",
    "\n",
    "edges = create_edges(k_neigh, cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a dataset of sub-graphs from the testing volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_test = []\n",
    "\n",
    "for i in range(x_test.size()[0]):\n",
    "    data_list_test.append(Data(x=x_test[i], edge_index=edges, y=y_test[i]))\n",
    "\n",
    "test_loader = DataLoader(data_list_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eval_Test:\n",
    "\n",
    "  def __init__(self, model, device):\n",
    "       \n",
    "    self.model = model\n",
    "    self.device = device\n",
    "\n",
    "  def eval_function(self, data_loader):\n",
    "\n",
    "    # Sets model to train mode\n",
    "    self.model.eval()\n",
    "\n",
    "    data_loader = data_loader\n",
    "\n",
    "    preds = torch.zeros((args['num_classes'],1)).cpu()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")): #remind that tqdm draws progress bars\n",
    "\n",
    "      model = self.model.to(device)\n",
    "      \n",
    "      batch = batch.to(device)\n",
    "\n",
    "      batch_index = batch.batch\n",
    "\n",
    "      edge_index = batch.edge_index.type(torch.LongTensor).to(device)\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        preds = torch.cat((preds,torch.nn.functional.softmax(model((batch.x).float(), edge_index, batch_index).transpose(1,0).cpu(), dim=0)),1)\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "      del(batch)\n",
    "      del(batch_index)\n",
    "      del(edge_index)\n",
    "      gc.collect()\n",
    "      \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test each trained GNN model (10 in total) on the sub-volumes extracted from the synthetic volume.\n",
    "We reconstruct 6 probability volumes (one for each class) and we assign to each voxel the highest probability class. We compute the dice score for each trained model and we write it on an external file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of Steps to reconstruct the original volume from the evaluation on the sub-volumes:\n",
    "steps = int((side - new_side) / stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "  model = GNN(args['heads'], args['num_features'], args['hidden'], args['num_classes'], args['dropout']).to(device)\n",
    "  model.load_state_dict(torch.load('GNN_200_non_augm_' + str(i) + '.h5'))\n",
    "  model.eval()\n",
    "\n",
    "  eval_obj = Eval_Test(model, device)\n",
    "\n",
    "\n",
    "  preds = eval_obj.eval_function(test_loader)\n",
    "\n",
    "\n",
    "  all_preds = preds[:,1:].reshape(args['num_classes'], steps, steps, steps, new_side, new_side, new_side)\n",
    "\n",
    "\n",
    "  summed_preds = torch.zeros(args['num_classes'], side,side,side)\n",
    "\n",
    "\n",
    "  for l in range(args['num_classes']):\n",
    "      for i in range(steps):\n",
    "          for j in range(steps):\n",
    "              for k in range(steps):\n",
    "                  summed_preds[l,(i)*stride:(i)*stride+new_side, \n",
    "                  (j)*stride:(j)*stride+new_side, \n",
    "                  (k)*stride:(k)*stride+new_side] = summed_preds[l,(i)*stride:(i)*stride+new_side, \n",
    "                  (j)*stride:(j)*stride+new_side, \n",
    "                  (k)*stride:(k)*stride+new_side] + all_preds[l, i, j, k, :, :, :]\n",
    "\n",
    "\n",
    "  preds_argmax = torch.argmax(summed_preds, dim=0)\n",
    "\n",
    "  # We plot the predicted segmentation of the first slice\n",
    "\n",
    "  plt.imshow(preds_argmax[0], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_Gnn_\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  DICE = dice(preds_argmax, labels_test, average='none', num_classes=args['num_classes'])\n",
    "\n",
    "  data = [i, 100 * DICE[0], 100 * DICE[1], 100 * DICE[2],\n",
    "          100 * DICE[3], 100 * DICE[4], 100 * DICE[5]]\n",
    "\n",
    "  with open('Dice_Test_Synthetic_gnn_200_non_augm.csv', 'a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

