{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "from utils import*\n",
    "from models import*\n",
    "from seed_everything import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Hyperparameters of the model\n",
    "\n",
    "args = {\n",
    "    'device': device,\n",
    "    'heads': 2,\n",
    "    'num_features' : 1,\n",
    "    'hidden' : 100, # 50 for ViG model\n",
    "    'num_classes' : 6,\n",
    "    'dropout': 0.001,\n",
    "    'alpha' : 0.1,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = 766\n",
    "\n",
    "class Train:\n",
    "\n",
    "  def __init__(self, model, device, data_loader, optimizer, loss_f):\n",
    "        \n",
    "    self.model = model\n",
    "    self.device = device\n",
    "    self.data_loader = data_loader\n",
    "    self.optimizer = optimizer\n",
    "    self.loss_f = loss_f\n",
    "\n",
    "  def train_function(self):\n",
    "\n",
    "    # Sets model to train mode\n",
    "    self.model.train()\n",
    "\n",
    "    loss_ = 0\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    model = self.model.to(device)\n",
    "\n",
    "    for step, batch in enumerate(tqdm(self.data_loader, desc=\"Iteration\")): #remind that tqdm draws progress bars\n",
    "\n",
    "\n",
    "      batch = batch.to(device)\n",
    "      batch_index = batch.batch\n",
    "      edge_index = (batch.edge_index).type(torch.LongTensor).to(device)\n",
    "\n",
    "      out = model((batch.x).float(), edge_index, batch_index) #Feed the data into the model\n",
    "      loss_ = self.loss_f(out, batch.y.to(torch.int64))\n",
    "\n",
    "      # backpropagate\n",
    "\n",
    "      if count % 8 == 0: # we backpropagate every 8 steps to simulate a batch size of 64\n",
    " \n",
    "        loss_.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad() #Zero grad the optimizer\n",
    "\n",
    "      else:\n",
    "\n",
    "        loss_.backward()\n",
    "\n",
    "      count += 1  \n",
    "      \n",
    "      torch.cuda.empty_cache()\n",
    "      del(batch)\n",
    "      del(edge_index)\n",
    "      del(batch_index)\n",
    "      gc.collect()\n",
    "\n",
    "      if step != stop-2: # we eliminate the loss vector to free memory for each step apart from the last one\n",
    "        del(loss_)\n",
    "        gc.collect()\n",
    "\n",
    "    return loss_.item()\n",
    "  \n",
    "class Eval:\n",
    "\n",
    "  def __init__(self, model, device):\n",
    "        \n",
    "    self.model = model\n",
    "    self.device = device\n",
    "\n",
    "  def eval_function(self, data_loader):\n",
    "\n",
    "    # Sets model to eval mode\n",
    "    self.model.eval()\n",
    "    data_loader = data_loader\n",
    "\n",
    "    dice_per_class = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")): #remind that tqdm draws progress bars\n",
    "\n",
    "      model = self.model.to(device)\n",
    "\n",
    "      batch = batch.to(device)\n",
    "\n",
    "      batch_index = batch.batch\n",
    "\n",
    "      edge_index = batch.edge_index.type(torch.LongTensor).to(device)\n",
    "\n",
    "      with torch.no_grad():\n",
    "        pred = torch.argmax(model((batch.x).float(), edge_index, batch_index),\n",
    "                                axis=1)\n",
    "        y_true = batch.y.view(pred.shape)\n",
    "        y_pred = pred\n",
    "            \n",
    "      \n",
    "      torch.cuda.empty_cache()\n",
    "      del(batch)\n",
    "      del(batch_index)\n",
    "      del(edge_index)\n",
    "      gc.collect()\n",
    "\n",
    "      dice_per_class.append(Tensor.numpy(dice(y_pred, y_true, average='none', num_classes=args['num_classes']).detach().cpu()))\n",
    "      \n",
    "    mean_dice_per_class = np.mean(np.array(dice_per_class), axis=0)\n",
    "\n",
    "    return mean_dice_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 512 # The side of the original volume\n",
    "new_side = 64 # The side of the sub-volume on which we construct the graph\n",
    "stride = 56 # The stride we use in extracting the overlapping sub-volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the features and the labels of the 8 synthetic volumes (train/val and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = raw_to_tensor(\"FINAL1.raw\", side)\n",
    "\n",
    "features_2 = raw_to_tensor(\"FINAL2.raw\", side)\n",
    "\n",
    "features_3 = raw_to_tensor(\"FINAL3.raw\", side)\n",
    "\n",
    "features_4 = raw_to_tensor(\"FINAL4.raw\", side)\n",
    "\n",
    "features_5 = raw_to_tensor(\"FINAL5.raw\", side)\n",
    "\n",
    "features_6 = raw_to_tensor(\"FINAL6.raw\", side)\n",
    "\n",
    "features_7 = raw_to_tensor(\"FINAL7.raw\", side)\n",
    "\n",
    "features_test = raw_to_tensor(\"CVSynth.raw\", side)\n",
    "\n",
    "\n",
    "\n",
    "labels_1 = raw_to_tensor(\"LABELS1.raw\", side)\n",
    "\n",
    "labels_2 = raw_to_tensor(\"LABELS2.raw\", side)\n",
    "\n",
    "labels_3 = raw_to_tensor(\"LABELS3.raw\", side)\n",
    "\n",
    "labels_4 = raw_to_tensor(\"LABELS4.raw\", side)\n",
    "\n",
    "labels_5 = raw_to_tensor(\"LABELS5.raw\", side)\n",
    "\n",
    "labels_6 = raw_to_tensor(\"LABELS6.raw\", side)\n",
    "\n",
    "labels_7 = raw_to_tensor(\"LABELS7.raw\", side)\n",
    "\n",
    "labels_test = raw_to_tensor(\"CVSynth_Labels.raw\", side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the average occurrence of the 6 classes among the 8 volumes (train/val and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_1 = average_labels_vol(labels_1,side)\n",
    "occ_2 = average_labels_vol(labels_2,side)\n",
    "occ_3 = average_labels_vol(labels_3,side)\n",
    "occ_4 = average_labels_vol(labels_4,side)\n",
    "occ_5 = average_labels_vol(labels_5,side)\n",
    "occ_6 = average_labels_vol(labels_6,side)\n",
    "occ_7 = average_labels_vol(labels_7,side)\n",
    "occ_test = average_labels_vol(labels_test,side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = (np.array(occ_1) + np.array(occ_2) + np.array(occ_3) + np.array(occ_4) + np.array(occ_5) + np.array(occ_6) + np.array(occ_7) + np.array(occ_test))/7\n",
    "\n",
    "norm_av = (av[:])/(np.sum(av[:]))\n",
    "inverse_norm_av = (1/norm_av).reshape(-1)\n",
    "inverse_norm_av = torch.tensor(inverse_norm_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract 64x64x64 overlapping sub-volumes from the original volumes with a stride of 56. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(view_as_windows(features_1.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "x2 = torch.tensor(view_as_windows(features_2.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "x3 = torch.tensor(view_as_windows(features_3.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "x4 = torch.tensor(view_as_windows(features_4.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "x5 = torch.tensor(view_as_windows(features_5.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "x6 = torch.tensor(view_as_windows(features_6.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "x7 = torch.tensor(view_as_windows(features_7.numpy(), (64,64,64), step=stride).reshape(-1,64**3,1))\n",
    "\n",
    "\n",
    "y1 = torch.tensor(view_as_windows(labels_1.numpy(), (64,64,64), step=stride).reshape(-1,64**3))\n",
    "\n",
    "y2 = torch.tensor(view_as_windows(labels_2.numpy(), (64,64,64), step=stride).reshape(-1,64**3))\n",
    "\n",
    "y3 = torch.tensor(view_as_windows(labels_3.numpy(), (64,64,64), step=stride).reshape(-1,64**3))\n",
    "\n",
    "y4 = torch.tensor(view_as_windows(labels_4.numpy(), (64,64,64), step=stride).reshape(-1,64**3))\n",
    "\n",
    "y5 = torch.tensor(view_as_windows(labels_5.numpy(), (64,64,64), step=stride).reshape(-1,64**3))\n",
    "\n",
    "y6 = torch.tensor(view_as_windows(labels_6.numpy(), (64,64,64), step=stride).reshape(-1,64**3))\n",
    "\n",
    "y7 = torch.tensor(view_as_windows(labels_7.numpy(), (64,64,64), step=stride).reshape(-1,64**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a graph from each sub-volume by connecting each voxel to its nearest 6 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neigh = 6\n",
    "cloud = torch.cartesian_prod(torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)))\n",
    "edges = create_edges(k_neigh, cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the dataset for training and validation after shuffling the subvolumes from the first 7 volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "def data_list_creation(X, Y, edges):\n",
    "  for i in range(X.size()[0]):\n",
    "    data_list.append(Data(x=X[i], edge_index=edges, y=Y[i]))\n",
    "\n",
    "data_list_creation(x1, y1, edges)\n",
    "data_list_creation(x2, y2, edges)\n",
    "data_list_creation(x3, y3, edges)\n",
    "data_list_creation(x4, y4, edges)\n",
    "data_list_creation(x5, y5, edges)\n",
    "data_list_creation(x6, y6, edges)\n",
    "data_list_creation(x7, y7, edges)\n",
    "\n",
    "random.Random(4).shuffle(data_list) # We fix it to make it reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the adjacency matrix of the graph occupies a lot of memory, we set the batch size to 4 and backpropagate every 8 steps to simulate a batch size of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list[:int(0.6*len(data_list))], batch_size=batch, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(data_list[int(0.6*len(data_list)):], batch_size=batch, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the stop variable to eliminate the loss vector from memory while training the model until the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data_list[:int(0.6*len(data_list))]) % batch == 0:\n",
    "  stop = len(data_list[:int(0.6*len(data_list))])/batch\n",
    "else:\n",
    "  stop = len(data_list[:int(0.6*len(data_list))])//batch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'GNN_non_augm') # directory in which we save the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    seed_everything(i) # we fix it to make it reproducible\n",
    "\n",
    "    model = GNN(args['heads'], args['num_features'], args['hidden'], args['num_classes'], args['dropout']).to(device)\n",
    "    model.reset_parameters()\n",
    "    losses = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=0.001)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=inverse_norm_av.type(torch.FloatTensor).to(device)) \n",
    "\n",
    "    decayRate = 0.96\n",
    "    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "\n",
    "    for epoch in range(1, 1 + args['epochs']): #\n",
    "        \n",
    "        print('Training...')\n",
    "        model = model.float()\n",
    "        train_obj = Train(model, device, train_loader, optimizer, loss_fn)\n",
    "        loss = train_obj.train_function()\n",
    "        losses.append(loss)\n",
    "        my_lr_scheduler.step()\n",
    "\n",
    "        if epoch == args['epochs']:\n",
    "          \n",
    "          eval_obj = Eval(model, device)\n",
    "          train_acc_per_class = eval_obj.eval_function(train_loader) \n",
    "          val_acc_per_class = eval_obj.eval_function(val_loader) \n",
    "        \n",
    "          data = [i, 100 * train_acc_per_class[0], 100 * train_acc_per_class[1], 100 * train_acc_per_class[2],\n",
    "                  100 * train_acc_per_class[3], 100 * train_acc_per_class[4], 100 * train_acc_per_class[5],\n",
    "                  100 * val_acc_per_class[0], 100 * val_acc_per_class[1], 100 * val_acc_per_class[2],\n",
    "                  100 * val_acc_per_class[3], 100 * val_acc_per_class[4], 100 * val_acc_per_class[5]]\n",
    "          \n",
    "          with open('Train_Val_Synthetic_GNN.csv', 'a') as f:\n",
    "              writer = csv.writer(f)\n",
    "              writer.writerow(data)\n",
    "        \n",
    "    model_name = 'GNN_200_non_augm_' + str(i) + '.h5'\n",
    "\n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    plt.plot(range(len(losses)), losses)\n",
    "    plt.title(\"Loss on the training set\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss_GNN_200_non_augm_\" + str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michelaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
