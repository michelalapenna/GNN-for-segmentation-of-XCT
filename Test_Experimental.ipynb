{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "from utils import*\n",
    "from models import*\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Hyperparameters of the model\n",
    "args = {\n",
    "    'device': device,\n",
    "    'heads': 2,\n",
    "    'num_features' : 1,\n",
    "    'hidden' : 100,\n",
    "    'num_classes' : 6,\n",
    "    'dropout': 0.001,\n",
    "    'alpha' : 0.1,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 200,\n",
    "}\n",
    "\n",
    "\n",
    "side = 512 # The side of the original volume\n",
    "new_side = 64 # The side of the sub-volume on which we construct the graph\n",
    "stride = 28 # The stride we use in extracting the overlapping sub-volumes\n",
    "\n",
    "\n",
    "# We import the four experimental volumes\n",
    "\n",
    "features_1_exp = raw_to_tensor(\"CV1_NLM8.raw\", side)\n",
    "\n",
    "features_2_exp = raw_to_tensor(\"CV2_NLM8.raw\", side)\n",
    "\n",
    "features_3_exp = raw_to_tensor(\"CV3_NLM8.raw\", side)\n",
    "\n",
    "features_4_exp = raw_to_tensor(\"CV4_NLM8.raw\", side)\n",
    "\n",
    "# And we extract the sub-volumes\n",
    "\n",
    "x_1_exp = torch.tensor(view_as_windows(features_1_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "x_2_exp = torch.tensor(view_as_windows(features_2_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "x_3_exp = torch.tensor(view_as_windows(features_3_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "x_4_exp = torch.tensor(view_as_windows(features_4_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "\n",
    "# Then we import the four manually-labelled slices, one for each volume\n",
    "\n",
    "labels_1_exp = tif_to_tensor(\"CV1 Labels - Slice 339.tif\", side)\n",
    "\n",
    "labels_2_exp = tif_to_tensor(\"CV2 Labels - Slice 139.tif\", side)\n",
    "\n",
    "labels_3_exp = tif_to_tensor(\"CV3 Labels - Slice 219.tif\", side)\n",
    "\n",
    "labels_4_exp = tif_to_tensor(\"CV4 Labels - Slice 059.tif\", side)\n",
    "\n",
    "# We create a list of edges connecting each node to its first 6 neighbors\n",
    "\n",
    "cloud = torch.cartesian_prod(torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)))\n",
    "\n",
    "k_neigh = 6\n",
    "\n",
    "edges = create_edges(k_neigh, cloud)\n",
    "\n",
    "# We define the test function\n",
    "\n",
    "batch = 1\n",
    "\n",
    "\n",
    "class Eval_Test:\n",
    "\n",
    "  def __init__(self, model, device):\n",
    "       \n",
    "    self.model = model\n",
    "    self.device = device\n",
    "\n",
    "  def eval_function(self, data_loader):\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    data_loader = data_loader\n",
    "\n",
    "    preds = torch.zeros((args['num_classes'],1)).cpu()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")): #remind that tqdm draws progress bars\n",
    "\n",
    "      model = self.model.to(device)\n",
    "      \n",
    "      batch = batch.to(device)\n",
    "\n",
    "      batch_index = batch.batch\n",
    "\n",
    "      edge_index = batch.edge_index.type(torch.LongTensor).to(device)\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        preds = torch.cat((preds,torch.nn.functional.softmax(model((batch.x).float(), edge_index, batch_index).transpose(1,0).cpu(), dim=0)),1)\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "      del(batch)\n",
    "      del(batch_index)\n",
    "      del(edge_index)\n",
    "      gc.collect()\n",
    "      \n",
    "    return preds\n",
    "\n",
    "\n",
    "#The number of Steps to reconstruct the original volume from the evaluation on the sub-volumes:\n",
    "steps = int((side - new_side) / stride + 1)\n",
    "\n",
    "def extract_overlap_pred(eval_obj, test_loader):\n",
    "    \n",
    "  preds = eval_obj.eval_function(test_loader)\n",
    "\n",
    "\n",
    "  all_preds = preds[:,1:].reshape(args['num_classes'], steps, steps, steps, new_side, new_side, new_side)\n",
    "\n",
    "\n",
    "  summed_preds = torch.zeros(args['num_classes'], side,side,side)\n",
    "\n",
    "\n",
    "  for l in range(args['num_classes']):\n",
    "      for i in range(steps):\n",
    "          for j in range(steps):\n",
    "              for k in range(steps):\n",
    "                  summed_preds[l,(i)*stride:(i)*stride+new_side, \n",
    "                  (j)*stride:(j)*stride+new_side, \n",
    "                  (k)*stride:(k)*stride+new_side] = summed_preds[l,(i)*stride:(i)*stride+new_side, \n",
    "                  (j)*stride:(j)*stride+new_side, \n",
    "                  (k)*stride:(k)*stride+new_side] + all_preds[l, i, j, k, :, :, :]\n",
    "\n",
    "\n",
    "  preds_argmax = torch.argmax(summed_preds, dim=0)\n",
    "\n",
    "  return preds_argmax\n",
    "\n",
    "# We plot the four manually-labelled slices to compare them with the model's segmentation\n",
    "\n",
    "plt.imshow(labels_1_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_1\")\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(labels_2_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_2\")\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(labels_3_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_3\")\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(labels_4_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_4\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# We construct a dataset of sub-graphs from every experimental volume\n",
    "\n",
    "data_list_test_1 = []\n",
    "\n",
    "for i in range(x_1_exp.size()[0]):\n",
    "    data_list_test_1.append(Data(x=x_1_exp[i], edge_index=edges, y=labels_1_exp))\n",
    "\n",
    "test_loader_1 = DataLoader(data_list_test_1, batch_size=1, shuffle=False)\n",
    "\n",
    "data_list_test_2 = []\n",
    "\n",
    "for i in range(x_2_exp.size()[0]):\n",
    "    data_list_test_2.append(Data(x=x_2_exp[i], edge_index=edges, y=labels_2_exp))\n",
    "\n",
    "test_loader_2 = DataLoader(data_list_test_2, batch_size=1, shuffle=False)\n",
    "\n",
    "data_list_test_3 = []\n",
    "\n",
    "for i in range(x_3_exp.size()[0]):\n",
    "    data_list_test_3.append(Data(x=x_3_exp[i], edge_index=edges, y=labels_3_exp))\n",
    "\n",
    "test_loader_3 = DataLoader(data_list_test_3, batch_size=1, shuffle=False)\n",
    "\n",
    "data_list_test_4 = []\n",
    "\n",
    "for i in range(x_4_exp.size()[0]):\n",
    "    data_list_test_4.append(Data(x=x_4_exp[i], edge_index=edges, y=labels_4_exp))\n",
    "\n",
    "test_loader_4 = DataLoader(data_list_test_4, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# We test each trained GNN model (10 in total) on the sub-volumes extracted from the four experimental volumes.\n",
    "# For each experimental volume, we reconstruct 6 probability volumes (one for each class) and we assign to \n",
    "# each voxel the highest probability class.\n",
    "# We compute the dice score only for the manually-labelled slices and we write it on an external file.\n",
    " \n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "  model = GNN(args['heads'], args['num_features'], args['hidden'], args['num_classes'], args['dropout']).to(device)\n",
    "  model.load_state_dict(torch.load('GNN_200_non_augm_' + str(i) + '.h5'))\n",
    "  model.eval()\n",
    "\n",
    "  eval_obj = Eval_Test(model, device)\n",
    "\n",
    "  preds_1 = extract_overlap_pred(eval_obj, test_loader_1)\n",
    "\n",
    "  plt.imshow(preds_1[339], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_1\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_1 = dice(preds_1[339], labels_1_exp, average='none', num_classes=6)\n",
    "  data_1 = [i, 100 * dice_1[0].numpy(), 100 * dice_1[1].numpy(), 100 * dice_1[2].numpy(),\n",
    "          100 * dice_1[3].numpy(), 100 * dice_1[4].numpy(), 100 * dice_1[5].numpy()]\n",
    "\n",
    "  preds_2 = extract_overlap_pred(eval_obj, test_loader_2)\n",
    "\n",
    "  labels_2_exp[labels_2_exp == 6] = 0\n",
    "\n",
    "  plt.imshow(preds_2[139], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_2\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_2 = dice(preds_2[139], labels_2_exp, average='none', num_classes=6)\n",
    "  data_2 = [i, 100 * dice_2[0].numpy(), 100 * dice_2[1].numpy(), 100 * dice_2[2].numpy(),\n",
    "          100 * dice_2[3].numpy(), 100 * dice_2[4].numpy(), 100 * dice_2[5].numpy()]\n",
    "\n",
    "  preds_3 = extract_overlap_pred(eval_obj, test_loader_3)\n",
    "\n",
    "  labels_3_exp[labels_3_exp == 6] = 0\n",
    "\n",
    "  plt.imshow(preds_3[219], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_3\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_3 = dice(preds_3[219], labels_3_exp, average='none', num_classes=6)\n",
    "  data_3 = [i, 100 * dice_3[0].numpy(), 100 * dice_3[1].numpy(), 100 * dice_3[2].numpy(),\n",
    "          100 * dice_3[3].numpy(), 100 * dice_3[4].numpy(), 100 * dice_3[5].numpy()]\n",
    "\n",
    "  preds_4 = extract_overlap_pred(eval_obj, test_loader_4)\n",
    "\n",
    "  labels_4_exp[labels_4_exp == 6] = 0\n",
    "\n",
    "  plt.imshow(preds_4[59], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_4\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_4 = dice(preds_4[59], labels_4_exp, average='none', num_classes=6)\n",
    "  data_4 = [i, 100 * dice_4[0].numpy(), 100 * dice_4[1].numpy(), 100 * dice_4[2].numpy(),\n",
    "          100 * dice_4[3].numpy(), 100 * dice_4[4].numpy(), 100 * dice_4[5].numpy()]\n",
    "\n",
    "  with open('Dice_Experimental_GNN.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data_1)\n",
    "        writer.writerow(data_2)\n",
    "        writer.writerow(data_3)\n",
    "        writer.writerow(data_4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michelaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
