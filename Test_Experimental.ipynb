{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ferdinando.zanchett2\\Desktop\\Thanos\\michelaenv\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ferdinando.zanchett2\\Desktop\\Thanos\\michelaenv\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947f973e22eb4a5294cf52eda26c05ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6c8d898fde4535b635f2866d64d778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e450424ffd264394a8ffdb7d5ad4443e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37e09a1c73f46c182b906d6f8fa9410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5391012d074b1f84b3bcdbc8c0b039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaf50c676a24ba597cf6e6fd49cec08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e31d26bf01471686ac18a040a5e303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd1ff98145148e58cee8b0fe5110531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fb2b3805cf4ab3b0c79e888bfa4518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19389fcef9d48e1bed7e1a518cd1eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1195926fa4f44b22b82670a9557f4731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2e13096d29486384f10868c879ac3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from imports import*\n",
    "from utils import*\n",
    "from models import*\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#Now let's train the network on the graphs\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "args = {\n",
    "    'device': device,\n",
    "    'heads': 2,\n",
    "    'num_features' : 1,\n",
    "    'hidden' : 100,\n",
    "    'num_classes' : 6,\n",
    "    'dropout': 0.001,\n",
    "    'alpha' : 0.1,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 200,\n",
    "}\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "side = 512\n",
    "new_side = 64\n",
    "stride = 28\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "features_1_exp = raw_to_tensor(\"CV1_NLM8.raw\", side)\n",
    "\n",
    "features_2_exp = raw_to_tensor(\"CV2_NLM8.raw\", side)\n",
    "\n",
    "features_3_exp = raw_to_tensor(\"CV3_NLM8.raw\", side)\n",
    "\n",
    "features_4_exp = raw_to_tensor(\"CV4_NLM8.raw\", side)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "x_1_exp = torch.tensor(view_as_windows(features_1_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "x_2_exp = torch.tensor(view_as_windows(features_2_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "x_3_exp = torch.tensor(view_as_windows(features_3_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "x_4_exp = torch.tensor(view_as_windows(features_4_exp.numpy(), (64,64,64), step=28).reshape(-1,64**3,1))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#labels_1_exp = tif_to_tensor(\"CV1LabelsSlice339.tif\", side)\n",
    "\n",
    "#labels_2_exp = tif_to_tensor(\"CV2LabelsSlice139.tif\", side)\n",
    "\n",
    "#labels_3_exp = tif_to_tensor(\"CV3LabelsSlice219.tif\", side)\n",
    "\n",
    "#labels_4_exp = tif_to_tensor(\"CV4LabelsSlice059.tif\", side)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "labels_1_exp = tif_to_tensor(\"CV1 Labels - Slice 339.tif\", side)\n",
    "\n",
    "labels_2_exp = tif_to_tensor(\"CV2 Labels - Slice 139.tif\", side)\n",
    "\n",
    "labels_3_exp = tif_to_tensor(\"CV3 Labels - Slice 219.tif\", side)\n",
    "\n",
    "labels_4_exp = tif_to_tensor(\"CV4 Labels - Slice 059.tif\", side)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "new_side = 64\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "cloud = torch.cartesian_prod(torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)), torch.tensor(range(0, new_side)))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "k_neigh = 6\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "edges = create_edges(k_neigh, cloud)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "batch = 1\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class Eval_Test:\n",
    "\n",
    "  def __init__(self, model, device):\n",
    "       \n",
    "    self.model = model\n",
    "    self.device = device\n",
    "\n",
    "  def eval_function(self, data_loader):\n",
    "\n",
    "    # Sets model to train mode\n",
    "    self.model.eval()\n",
    "\n",
    "    data_loader = data_loader\n",
    "\n",
    "    preds = torch.zeros((6,1)).cpu()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")): #remind that tqdm draws progress bars\n",
    "\n",
    "      model = self.model.to(device)\n",
    "      \n",
    "      batch = batch.to(device)\n",
    "\n",
    "      batch_index = batch.batch\n",
    "\n",
    "      edge_index = batch.edge_index.type(torch.LongTensor).to(device)\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        preds = torch.cat((preds,torch.nn.functional.softmax(model((batch.x).float(), edge_index, batch_index).transpose(1,0).cpu(), dim=0)),1)\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "      del(batch)\n",
    "      del(batch_index)\n",
    "      del(edge_index)\n",
    "      gc.collect()\n",
    "      \n",
    "    return preds\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Define Volume Size of the whole Volume (cube Size):\n",
    "Vol_Size = 512\n",
    "#Define Volume Size of the input (minibatch) Volume (minibatch cube Size):\n",
    "MinBatch_Vol_Size = 64\n",
    "#Define Stride:\n",
    "Stride = 28\n",
    "\n",
    "#Therefore the number of Steps are:\n",
    "Steps = int((Vol_Size - MinBatch_Vol_Size) / Stride + 1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def extract_overlap_pred(eval_obj, test_loader):\n",
    "    \n",
    "  preds = eval_obj.eval_function(test_loader)\n",
    "\n",
    "\n",
    "  all_preds = preds[:,1:].reshape(6, 17, 17, 17, 64, 64, 64)\n",
    "\n",
    "\n",
    "  summed_preds = torch.zeros(6, 512,512,512)\n",
    "\n",
    "\n",
    "  for l in range(6):\n",
    "      for i in range(Steps):\n",
    "          for j in range(Steps):\n",
    "              for k in range(Steps):\n",
    "                  summed_preds[l,(i)*Stride:(i)*Stride+MinBatch_Vol_Size, \n",
    "                  (j)*Stride:(j)*Stride+MinBatch_Vol_Size, \n",
    "                  (k)*Stride:(k)*Stride+MinBatch_Vol_Size] = summed_preds[l,(i)*Stride:(i)*Stride+MinBatch_Vol_Size, \n",
    "                  (j)*Stride:(j)*Stride+MinBatch_Vol_Size, \n",
    "                  (k)*Stride:(k)*Stride+MinBatch_Vol_Size] + all_preds[l, i, j, k, :, :, :]\n",
    "\n",
    "\n",
    "  preds_argmax = torch.argmax(summed_preds, dim=0)\n",
    "\n",
    "  return preds_argmax\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plt.imshow(labels_1_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_1\")\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(labels_2_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_2\")\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(labels_3_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_3\")\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(labels_4_exp, vmin=0, vmax=5)\n",
    "plt.savefig(\"Labels_4\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data_list_test_1 = []\n",
    "\n",
    "for i in range(x_1_exp.size()[0]):\n",
    "    data_list_test_1.append(Data(x=x_1_exp[i], edge_index=edges, y=labels_1_exp))\n",
    "\n",
    "test_loader_1 = DataLoader(data_list_test_1, batch_size=1, shuffle=False)\n",
    "\n",
    "data_list_test_2 = []\n",
    "\n",
    "for i in range(x_2_exp.size()[0]):\n",
    "    data_list_test_2.append(Data(x=x_2_exp[i], edge_index=edges, y=labels_2_exp))\n",
    "\n",
    "test_loader_2 = DataLoader(data_list_test_2, batch_size=1, shuffle=False)\n",
    "\n",
    "data_list_test_3 = []\n",
    "\n",
    "for i in range(x_3_exp.size()[0]):\n",
    "    data_list_test_3.append(Data(x=x_3_exp[i], edge_index=edges, y=labels_3_exp))\n",
    "\n",
    "test_loader_3 = DataLoader(data_list_test_3, batch_size=1, shuffle=False)\n",
    "\n",
    "data_list_test_4 = []\n",
    "\n",
    "for i in range(x_4_exp.size()[0]):\n",
    "    data_list_test_4.append(Data(x=x_4_exp[i], edge_index=edges, y=labels_4_exp))\n",
    "\n",
    "test_loader_4 = DataLoader(data_list_test_4, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "  model = GNN(args['heads'], args['num_features'], args['hidden'], args['num_classes'], args['dropout']).to(device)\n",
    "  model.load_state_dict(torch.load('GNN_200_non_augm_' + str(i) + '.h5'))\n",
    "  model.eval()\n",
    "\n",
    "  eval_obj = Eval_Test(model, device)\n",
    "\n",
    "  preds_1 = extract_overlap_pred(eval_obj, test_loader_1)\n",
    "\n",
    "  plt.imshow(preds_1[339], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_1\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_1 = dice(preds_1[339], labels_1_exp, average='none', num_classes=6)\n",
    "  data_1 = [i, 100 * dice_1[0].numpy(), 100 * dice_1[1].numpy(), 100 * dice_1[2].numpy(),  #added\n",
    "          100 * dice_1[3].numpy(), 100 * dice_1[4].numpy(), 100 * dice_1[5].numpy()]\n",
    "\n",
    "  preds_2 = extract_overlap_pred(eval_obj, test_loader_2)\n",
    "\n",
    "  labels_2_exp[labels_2_exp == 6] = 0\n",
    "\n",
    "  plt.imshow(preds_2[139], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_2\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_2 = dice(preds_2[139], labels_2_exp, average='none', num_classes=6)\n",
    "  data_2 = [i, 100 * dice_2[0].numpy(), 100 * dice_2[1].numpy(), 100 * dice_2[2].numpy(),  #added\n",
    "          100 * dice_2[3].numpy(), 100 * dice_2[4].numpy(), 100 * dice_2[5].numpy()]\n",
    "\n",
    "  preds_3 = extract_overlap_pred(eval_obj, test_loader_3)\n",
    "\n",
    "  labels_3_exp[labels_3_exp == 6] = 0\n",
    "\n",
    "  plt.imshow(preds_3[219], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_3\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_3 = dice(preds_3[219], labels_3_exp, average='none', num_classes=6)\n",
    "  data_3 = [i, 100 * dice_3[0].numpy(), 100 * dice_3[1].numpy(), 100 * dice_3[2].numpy(),  #added\n",
    "          100 * dice_3[3].numpy(), 100 * dice_3[4].numpy(), 100 * dice_3[5].numpy()]\n",
    "\n",
    "  preds_4 = extract_overlap_pred(eval_obj, test_loader_4)\n",
    "\n",
    "  labels_4_exp[labels_4_exp == 6] = 0\n",
    "\n",
    "  plt.imshow(preds_4[59], vmin=0, vmax=5)\n",
    "  plt.savefig(\"Preds_4\" + str(i))\n",
    "  plt.close()\n",
    "\n",
    "  dice_4 = dice(preds_4[59], labels_4_exp, average='none', num_classes=6)\n",
    "  data_4 = [i, 100 * dice_4[0].numpy(), 100 * dice_4[1].numpy(), 100 * dice_4[2].numpy(), #added\n",
    "          100 * dice_4[3].numpy(), 100 * dice_4[4].numpy(), 100 * dice_4[5].numpy()]\n",
    "\n",
    "  with open('Dice_Experimental_GNN.csv', 'a') as f:   #modified\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data_1)\n",
    "        writer.writerow(data_2)\n",
    "        writer.writerow(data_3)\n",
    "        writer.writerow(data_4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michelaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
